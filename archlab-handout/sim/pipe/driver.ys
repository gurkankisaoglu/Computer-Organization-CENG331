#######################################################################
# Test for copying block of size 121;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $121, %rdx		# src and dst have 121 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	call check	        # Call checker code
	halt                    # should halt with 0xaaaa in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Gürkan Kısaoğlu
# 2171726
#
# Describe how and why you modified the baseline code.
#
# First i replaced all addq instructions with iaddq instruction since it combines
# two instructions(irmovq-addq) and increases performance.
# Second i implemented a loop unrolling which copies 10 elements in each turn, then i
# handled the remaining offset part with a jump table.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
ncopy:
	iaddq $-9, %rdx 
	jle Offset

Loop: 
	mrmovq (%rdi), %r8 
	mrmovq 8(%rdi), %r9 
	mrmovq 16(%rdi), %r10 
	mrmovq 24(%rdi), %r11 
	mrmovq 32(%rdi), %r12
	mrmovq 40(%rdi), %r13
	mrmovq 48(%rdi), %r14
	mrmovq 64(%rdi), %rcx
	rmmovq %r8, (%rsi)
	andq %r8, %r8 
	jle Node1 
	iaddq $1, %rax 

Node1:
	mrmovq 72(%rdi), %r8
	rmmovq %r9, 8(%rsi) 
	andq %r9, %r9 
	jle Node2
	iaddq $1, %rax

Node2:
	mrmovq 56(%rdi), %r9 
	rmmovq %r10, 16(%rsi) 
	andq %r10, %r10 
	jle Node3
	iaddq $1, %rax

Node3:
	rmmovq %r11, 24(%rsi) 
	andq %r11, %r11
	jle Node4
	iaddq $1, %rax

Node4:
	rmmovq %r12, 32(%rsi)
	andq %r12, %r12 
	jle Node5
	iaddq $1, %rax

Node5:
	rmmovq %r13, 40(%rsi)
	andq %r13, %r13
	jle Node6
	iaddq $1, %rax

Node6:
	rmmovq %r14, 48(%rsi)
	andq %r14, %r14
	jle Node7
	iaddq $1, %rax

Node7:
	rmmovq %r9, 56(%rsi)
	andq %r9, %r9
	jle Node8
	iaddq $1, %rax

Node8:
	rmmovq %rcx, 64(%rsi)
	andq %rcx, %rcx
	jle Node9
	iaddq $1, %rax

Node9:
	rmmovq %r8, 72(%rsi)
	andq %r8, %r8
	jle Loop_Control
	iaddq $1, %rax

Loop_Control:
	iaddq $80, %rdi 
	iaddq $80, %rsi 
	iaddq $-10, %rdx 
	jg Loop 

Offset:
	addq %rdx, %rdx 
	addq %rdx, %rdx 
	addq %rdx, %rdx 
	mrmovq PostTable(%rdx), %rdx 
	mrmovq (%rdi), %r8 
	mrmovq 8(%rdi), %r9
	pushq %rdx 
	ret 

#.align 8
	.quad Done
	.quad offset1
	.quad offset2
	.quad offset3
	.quad offset4
	.quad offset5
	.quad offset6
	.quad offset7
	.quad offset8
PostTable:
	.quad offset9


offset9: 
	mrmovq 64(%rdi), %r11 
	mrmovq 56(%rdi), %r10
	rmmovq %r11, 64(%rsi) 
	andq %r11, %r11
	jle offset8_f
	iaddq $1, %rax

offset8: 
	mrmovq 56(%rdi), %r10 
offset8_f:
	mrmovq 48(%rdi), %r11 
	rmmovq %r10, 56(%rsi) 
	andq %r10, %r10 
	jle offset7_f
	iaddq $1, %rax

offset7:
	mrmovq 48(%rdi), %r11
offset7_f:
	mrmovq 40(%rdi), %r10
	rmmovq %r11, 48(%rsi)
	andq %r11, %r11
	jle offset6_f
	iaddq $1, %rax

offset6:
	mrmovq 40(%rdi), %r10
offset6_f:
	mrmovq 32(%rdi), %r11
	rmmovq %r10, 40(%rsi)
	andq %r10, %r10
	jle offset5_f
	iaddq $1, %rax

offset5:
	mrmovq 32(%rdi), %r11
offset5_f:
	mrmovq 24(%rdi), %r10
	rmmovq %r11, 32(%rsi)
	andq %r11, %r11
	jle offset4_f
	iaddq $1, %rax

offset4:
	mrmovq 24(%rdi), %r10
offset4_f:
	mrmovq 16(%rdi), %r11
	rmmovq %r10, 24(%rsi)
	andq %r10, %r10
	jle offset3_f
	iaddq $1, %rax

offset3:
	mrmovq 16(%rdi), %r11
offset3_f:
	rmmovq %r11, 16(%rsi)
	andq %r11, %r11
	jle offset2
	iaddq $1, %rax

offset2:
	rmmovq %r9, 8(%rsi)
	andq %r9, %r9
	jle offset1
	iaddq $1, %rax

offset1:
	rmmovq %r8, (%rsi)
	andq %r8, %r8
	jle 0x031
	iaddq $1, %rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:
#################################################################### 
# Epilogue code for the correctness testing driver
####################################################################

# This is the correctness checking code.
# It checks:
#   1. %rax has 52.  Set %rax to 0xbbbb if not.
#   2. The total length of the code is less than or equal to 1000.
#      Set %rax to 0xcccc if not.
#   3. The source data was copied to the destination.
#      Set %rax to 0xdddd if not.
#   4. The words just before and just after the destination region
#      were not corrupted.  Set %rax to 0xeeee if not.
# If all checks pass, then sets %rax to 0xaaaa
check:
	# Return value test
	irmovq $52,%r10
	subq %r10,%rax
	je checkb
	irmovq $0xbbbb,%rax  # Failed test #1
	jmp cdone
checkb:
	# Code length check
	irmovq EndFun,%rax
	irmovq StartFun,%rdx
	subq %rdx,%rax
	irmovq $1000,%rdx
	subq %rax,%rdx
	jge checkm
	irmovq $0xcccc,%rax  # Failed test #2
	jmp cdone
checkm:
	irmovq dest, %rdx # Pointer to next destination location
	irmovq src,%rbx   # Pointer to next source location
	irmovq $121,%rdi  # Count
	andq %rdi,%rdi
	je checkpre         # Skip check if count = 0
mcloop:
	mrmovq (%rdx),%rax
	mrmovq (%rbx),%rsi
	subq %rsi,%rax
	je  mok
	irmovq $0xdddd,%rax # Failed test #3
	jmp cdone
mok:
	irmovq $8,%rax
	addq %rax,%rdx	  # dest ++
	addq %rax,%rbx    # src++
	irmovq $1,%rax
	subq %rax,%rdi    # cnt--
	jg mcloop
checkpre:
	# Check for corruption
	irmovq Predest,%rdx
	mrmovq (%rdx), %rax  # Get word before destination
	irmovq $0xbcdefa, %rdx
	subq %rdx,%rax
	je checkpost
	irmovq $0xeeee,%rax  # Failed test #4
	jmp cdone
checkpost:
	# Check for corruption
	irmovq Postdest,%rdx
	mrmovq (%rdx), %rax  # Get word after destination
	irmovq $0xdefabc, %rdx
	subq %rdx,%rax
	je checkok
	irmovq $0xeeee,%rax # Failed test #4
	jmp cdone
checkok:
	# Successful checks
	irmovq $0xaaaa,%rax
cdone:
	ret

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad -2
	.quad -3
	.quad -4
	.quad -5
	.quad -6
	.quad 7
	.quad -8
	.quad -9
	.quad 10
	.quad 11
	.quad -12
	.quad 13
	.quad 14
	.quad -15
	.quad 16
	.quad 17
	.quad -18
	.quad 19
	.quad -20
	.quad -21
	.quad -22
	.quad -23
	.quad -24
	.quad 25
	.quad -26
	.quad 27
	.quad 28
	.quad -29
	.quad -30
	.quad 31
	.quad 32
	.quad -33
	.quad 34
	.quad -35
	.quad 36
	.quad 37
	.quad -38
	.quad -39
	.quad -40
	.quad 41
	.quad 42
	.quad -43
	.quad -44
	.quad -45
	.quad -46
	.quad -47
	.quad 48
	.quad 49
	.quad 50
	.quad -51
	.quad -52
	.quad 53
	.quad -54
	.quad -55
	.quad 56
	.quad -57
	.quad 58
	.quad -59
	.quad 60
	.quad -61
	.quad 62
	.quad -63
	.quad -64
	.quad -65
	.quad 66
	.quad 67
	.quad -68
	.quad -69
	.quad -70
	.quad -71
	.quad -72
	.quad 73
	.quad 74
	.quad -75
	.quad 76
	.quad -77
	.quad -78
	.quad -79
	.quad -80
	.quad 81
	.quad 82
	.quad -83
	.quad -84
	.quad -85
	.quad 86
	.quad -87
	.quad 88
	.quad -89
	.quad 90
	.quad 91
	.quad -92
	.quad -93
	.quad 94
	.quad 95
	.quad -96
	.quad 97
	.quad 98
	.quad 99
	.quad -100
	.quad -101
	.quad -102
	.quad -103
	.quad 104
	.quad -105
	.quad 106
	.quad 107
	.quad 108
	.quad -109
	.quad 110
	.quad -111
	.quad -112
	.quad 113
	.quad 114
	.quad -115
	.quad 116
	.quad -117
	.quad -118
	.quad -119
	.quad 120
	.quad -121
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
